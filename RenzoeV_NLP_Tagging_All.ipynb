{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RenzoeV_NLP Tagging_All.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k7LMPqJqZ_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34be9e25-eb5b-42c2-cc1a-e039cb3d9abc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "lOKUUF3Pppcf",
        "outputId": "5bbf7764-2b51-435e-9c66-4d99f49407e0"
      },
      "source": [
        "file_path = 'drive/MyDrive/+Renzoe Box/Administrative/Team Resources/Team Folders/Quhan Peng/RenzoeBoxV_sample800_NLP_trainingset_corrected.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "data.head(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>handle</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>vendor</th>\n",
              "      <th>type</th>\n",
              "      <th>tags</th>\n",
              "      <th>published</th>\n",
              "      <th>option1 name</th>\n",
              "      <th>option1 value</th>\n",
              "      <th>option2 name</th>\n",
              "      <th>option2 value</th>\n",
              "      <th>option3 name</th>\n",
              "      <th>option3 value</th>\n",
              "      <th>variant sku</th>\n",
              "      <th>variant grams</th>\n",
              "      <th>variant inventory tracker</th>\n",
              "      <th>variant inventory qty</th>\n",
              "      <th>variant inventory policy</th>\n",
              "      <th>variant fulfillment service</th>\n",
              "      <th>variant price</th>\n",
              "      <th>variant compare at price</th>\n",
              "      <th>variant requires shipping</th>\n",
              "      <th>variant taxable</th>\n",
              "      <th>variant barcode</th>\n",
              "      <th>image src</th>\n",
              "      <th>image position</th>\n",
              "      <th>image alt text</th>\n",
              "      <th>gift card</th>\n",
              "      <th>variant image</th>\n",
              "      <th>variant weight unit</th>\n",
              "      <th>cost per item</th>\n",
              "      <th>status</th>\n",
              "      <th>renzoe tags</th>\n",
              "      <th>id.1</th>\n",
              "      <th>unnamed: 0</th>\n",
              "      <th>unnamed: 0.1</th>\n",
              "      <th>pod nonpod</th>\n",
              "      <th>product type</th>\n",
              "      <th>coverage type</th>\n",
              "      <th>finish</th>\n",
              "      <th>skin concern</th>\n",
              "      <th>product consistency</th>\n",
              "      <th>product preference</th>\n",
              "      <th>other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1861.0</td>\n",
              "      <td>1462.0</td>\n",
              "      <td>bb-crayon-concealer-touch-up-stick</td>\n",
              "      <td>bb crayon concealer &amp; touch-up stick</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Erborian</td>\n",
              "      <td>bb &amp; cc creams</td>\n",
              "      <td>['face', 'non-pod']</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>Colors</td>\n",
              "      <td>Caramel (for tan to deep skin)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2569687</td>\n",
              "      <td>2.83495</td>\n",
              "      <td>Shopify</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Continue</td>\n",
              "      <td>manual</td>\n",
              "      <td>26.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://images.ulta.com/is/image/Ulta/2569686</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>['https://images.ulta.com/is/image/Ulta/256968...</td>\n",
              "      <td>g</td>\n",
              "      <td>26.0</td>\n",
              "      <td>draft</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13987.0</td>\n",
              "      <td>13987.0</td>\n",
              "      <td>pod, non-pod</td>\n",
              "      <td>Concealer</td>\n",
              "      <td>Medium Coverage</td>\n",
              "      <td>Semi-Matte</td>\n",
              "      <td>Blemishes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Clean Ingredients, Cruelty-Free, Gluten-Free</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0      id  ...                             product preference other\n",
              "0      1861.0  1462.0  ...  Clean Ingredients, Cruelty-Free, Gluten-Free    NaN\n",
              "\n",
              "[1 rows x 46 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1d0_BMlrkiw",
        "outputId": "9eb184bb-9c9c-42f3-ca5b-1a61f3dee8d0"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#set english stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVAz7DUbroHn"
      },
      "source": [
        "# Apply basic NLP for one piece of text\n",
        "def clean_text(text):\n",
        "#remove \\n\\w\\s, all lower case\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
        "    lst_text = text.split()\n",
        "    #Remove stopwords\n",
        "    lst_text = [word for word in lst_text if word not in stop_words]\n",
        "    #Stemming (remove -ing, -ly, ...)\n",
        "    ps = nltk.stem.porter.PorterStemmer()\n",
        "    lst_text = [ps.stem(word) for word in lst_text]\n",
        "    # Lemmatisation (convert the word into root word)\n",
        "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "    lst_text = [lem.lemmatize(word) for word in lst_text]\n",
        "    text = \" \".join(lst_text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Apply clean_text function the 'text' column for each row in df \n",
        "def NLPCleaning(df):\n",
        "    data = df.copy()\n",
        "    data[\"text\"] =data[\"text\"].apply(clean_text)\n",
        "    return data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVYXWW7w1KFp"
      },
      "source": [
        "def transferY(theY):\n",
        "  newY = []\n",
        "  for i in range(len(theY)):\n",
        "    new_item = theY.iloc[i].lower().split(', ')\n",
        "    newY.append(new_item)\n",
        "  return newY"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GklcRX6k0h3J"
      },
      "source": [
        "## Finish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQiToGmqsGCP"
      },
      "source": [
        "fdata = data[['handle', 'title', 'body','finish']]\n",
        "fdata = fdata.replace('-', np.nan)\n",
        "fdata.dropna(inplace = True)\n",
        "fdata = fdata.drop_duplicates()\n",
        "\n",
        "fdata = fdata[fdata[\"finish\"].str.contains(\"Metallic\")==False]\n",
        "fdata['text'] = fdata['handle'] + \" \" + fdata['title'] + \" \" + fdata['body']\n",
        "\n",
        "fdata = NLPCleaning(fdata)\n",
        "\n",
        "X_f = fdata['text']\n",
        "fdata_y = fdata['finish']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noAnrF8hss_3"
      },
      "source": [
        "for i in range(len(fdata_y)):\n",
        "\n",
        "  # fdata_y.values[i] = fdata_y.values[i].strip(\" \")\n",
        "\n",
        "  #replace all the typos\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Foundation', 'foundation')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Eyeshadow', 'eyeshadow')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Concealer', 'concealer')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Primer', 'primer')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Setting Powder', 'setting powder')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Eyeliner', 'eyeliner')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Brow Pencil/Powder/Gel', 'brow')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Brow Powder', 'brow')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('lip gloss', 'lip')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('lip liner', 'lip')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('lip stick', 'lip')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('lipstick', 'lip')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Lip Tint/Balm', 'lip')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Natural', 'natural')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Natural ', 'natural')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('natural ', 'natural')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Shimmer', 'shimmer')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Matte', 'matte')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Semi-Matte', 'semi-matte')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Sheer', 'sheer')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Metallic', 'metallic')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Mate', 'matte')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('matte ', 'matte')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Natrual', 'natural')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Semi-matte', 'semi-matte')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Dewy', 'dewy')\n",
        "  fdata_y.values[i] = fdata_y.values[i].replace('Glossy', 'glossy')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXTSOPN9AtIs"
      },
      "source": [
        "## Product Preference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3Lk98NQ0pIR"
      },
      "source": [
        "ppdata = data[['handle', 'title', 'body', 'product preference']]\n",
        "\n",
        "# Transfer every '-' to be NAN\n",
        "ppdata = ppdata.replace('-', np.nan)\n",
        "ppdata.dropna(axis = 0, inplace = True)\n",
        "ppdata.drop_duplicates(inplace = True, ignore_index = True)\n",
        "\n",
        "ppdata['text'] = ppdata['handle'] + \" \" + ppdata['title'] + \" \" + ppdata['body']\n",
        "\n",
        "ppdata = NLPCleaning(ppdata)\n",
        "ppdata_y = transferY(ppdata['product preference'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40cEJs9w1Sbc"
      },
      "source": [
        "# Using the resluts from the previous step, we need to manually\n",
        "\n",
        "# Correct all the typos and formate for y label\n",
        "for i in range(len(ppdata_y)):\n",
        "  for j in range(len(ppdata_y[i])):\n",
        "\n",
        "    #delete all the accident blank after words\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].strip(\" \")\n",
        "\n",
        "    # Replace all the typos!!!\n",
        "    # clean ingredients\n",
        "    # Cruelty Free\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('cruelty-free,long lasting', 'cruelty free')\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('cruelty-free', 'cruelty free')\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('cruelty-free. lengthening', 'cruelty free')\n",
        "    # Fragrance-Free\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('fragrance free', 'fragrance-free')\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('fragrance- free', 'fragrance-free')\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('fragrance-free,oil free', 'fragrance-free')\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('fragrnace free', 'fragrance-free')\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('fragrange free', 'fragrance-free')\n",
        "    # USA Made, Vegan, Minority Founded, SPF, Ethically Sourced, Trending, Protection\n",
        "    # Woman Founded\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('women founded', 'woman founded')\n",
        "    # Long Lasting\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('long  lasting', 'long lasting')\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('long wearing', 'long lasting')\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('long-lasting', 'long lasting')\n",
        "    ppdata_y[i][j] = ppdata_y[i][j].replace('longlasting', 'long lasting')\n",
        "\n",
        "ppdata.dropna(axis = 0, inplace = True)\n",
        "\n",
        "product_preference_cols = ['clean ingredients', 'cruelty free', 'fragrance-free', 'usa made', \n",
        "                           'vegan', 'minority founded', 'spf', 'ethically sourced', 'trending', \n",
        "                           'protection', 'woman founded', 'long lasting']\n",
        "\n",
        "valid_index = set()\n",
        "new_ppdata_y = []\n",
        "\n",
        "for i in range(len(ppdata_y)):\n",
        "  if all([item in product_preference_cols for item in ppdata_y[i]]):\n",
        "    # print(ppdata_y[i])\n",
        "    new_ppdata_y.append(ppdata_y[i])\n",
        "    valid_index.add(i)\n",
        "\n",
        "X_pp = ppdata.loc[valid_index, 'text']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj2T-Alw0maI"
      },
      "source": [
        "## Skin Concern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iyXN0p1CZL9"
      },
      "source": [
        "scdata = data[['handle', 'title', 'body','skin concern']]\n",
        "\n",
        "# transfer every '-' to be NAN\n",
        "scdata = scdata.replace('-', np.nan)\n",
        "scdata = scdata.dropna()\n",
        "scdata = scdata.drop_duplicates()\n",
        "\n",
        "scdata['text'] = scdata['handle'] + \" \" + scdata['title'] + \" \" + scdata['body']\n",
        "scdata = NLPCleaning(scdata)\n",
        "\n",
        "X_sc = scdata['text']\n",
        "scdata_y = transferY(scdata['skin concern'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js813iU7CZOp"
      },
      "source": [
        "# correct all the typos and formate for y label\n",
        "for i in range(len(scdata_y)):\n",
        "  for j in range(len(scdata_y[i])):\n",
        "    #delete all the accident blank after words\n",
        "    scdata_y[i][j] = scdata_y[i][j].rstrip(\" \")\n",
        "    #replace all the typos\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('blemishes', 'blemish')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('combiation', 'combination')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('combinatoin', 'combination')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('comination', 'combination')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('lines lines', 'fine lines')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('hyper pigmentation', 'hyperpigmentation')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('hyper pigmentatoins', 'hyperpigmentation')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('hypermpigmentaiton', 'hyperpigmentation')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('hyperpigmenation', 'hyperpigmentation')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('hyperpigmentaiton', 'hyperpigmentation')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('hyperpigmentations', 'hyperpigmentation')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('oliy', 'oily')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('large pores', 'pores')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('pores', 'large pores')\n",
        "    scdata_y[i][j] = scdata_y[i][j].replace('oil free', 'blemish')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iX5XKwFDxLj"
      },
      "source": [
        "## Coverage Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU1ahI9ZCZRZ"
      },
      "source": [
        "ctdata = data[['handle', 'title', 'body', 'coverage type']]\n",
        "\n",
        "# Transfer every '-' to be NAN\n",
        "ctdata = ctdata.replace('-', np.nan)\n",
        "ctdata.dropna(axis = 0, inplace = True)\n",
        "ctdata.drop_duplicates(inplace = True, ignore_index = True)\n",
        "\n",
        "ctdata['text'] = ctdata['handle'] + \" \" + ctdata['title'] + \" \" + ctdata['body']\n",
        "\n",
        "ctdata = NLPCleaning(ctdata)\n",
        "\n",
        "X_ct = ctdata['text']\n",
        "ctdata_y = ctdata['coverage type']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zILJ5w7bFW5A"
      },
      "source": [
        "# correct all the typos and formate for y label\n",
        "\n",
        "for i in range(len(ctdata_y)):\n",
        "\n",
        "  if(i >= len(ctdata_y)): break\n",
        "\n",
        "  if(ctdata_y.values[i] == ' ' or ctdata_y.values[i] == 'metallic'):\n",
        "    ctdata_y = ctdata_y.drop(ctdata_y.index[i])\n",
        "    X_ct.drop(X_ct.index[i], inplace = True)\n",
        "    continue\n",
        "\n",
        "  if(ctdata_y.values[i] == 'full'):\n",
        "    ctdata_y.values[i] = 'full coverage'\n",
        "    continue\n",
        "  \n",
        "  if(ctdata_y.values[i] == 'medium' or ctdata_y.values[i] == 'Medium'):\n",
        "    ctdata_y.values[i] = 'medium coverage'\n",
        "    continue\n",
        "\n",
        "for i in range(len(ctdata_y)):\n",
        "    \n",
        "    #delete all the accident blank after words\n",
        "    ctdata_y.values[i] = ctdata_y.values[i].rstrip(\" \")\n",
        "    #replace all the typos\n",
        "    ctdata_y.values[i] = ctdata_y.values[i].replace('Full Coverage', 'full coverage')\n",
        "    ctdata_y.values[i] = ctdata_y.values[i].replace('Full coverage', 'full coverage')\n",
        "    ctdata_y.values[i] = ctdata_y.values[i].replace('Medium Coverage', 'medium coverage')\n",
        "    ctdata_y.values[i] = ctdata_y.values[i].replace('Light Coverage', 'light coverage')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWppZeZSGQ7U",
        "outputId": "dbdafad2-9f64-4295-941d-e6edda4d1091"
      },
      "source": [
        "print(X_ct.shape)\n",
        "print(ctdata_y.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(152,)\n",
            "(152,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbPnLGIhHLim"
      },
      "source": [
        "## Product Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOis6g1ZHOQv"
      },
      "source": [
        "ptdata = data[['handle', 'title', 'body','product type']]\n",
        "\n",
        "# transfer every '-' to be NAN\n",
        "ptdata = ptdata.replace('-', np.nan)\n",
        "ptdata = ptdata.dropna()\n",
        "ptdata = ptdata.drop_duplicates()\n",
        "\n",
        "ptdata['text'] = ptdata['handle'] + \" \" + ptdata['title'] + \" \" + ptdata['body']\n",
        "ptdata = NLPCleaning(ptdata)\n",
        "\n",
        "ptdata = ptdata[~ptdata['product type'].isin(['duplicate?'])]  \n",
        "X_pt = ptdata['text']\n",
        "ptdata_y = ptdata['product type']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh_ZHv5bHOTs"
      },
      "source": [
        "for i in range(len(ptdata_y)):\n",
        "\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].lstrip(\" \")\n",
        "\n",
        "  #replace all the typos\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('Foundation', 'foundation')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('Eyeshadow', 'eyeshadow')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('Concealer', 'concealer')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('Primer', 'primer')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('Setting Powder', 'setting powder')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('Eyeliner', 'eyeliner')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('Brow Pencil/Powder/Gel', 'brow')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('Brow Powder', 'brow')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('lip gloss', 'lip')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('lip liner', 'lip')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('lip stick', 'lip')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('lipstick', 'lip')\n",
        "  ptdata_y.values[i] = ptdata_y.values[i].replace('Lip Tint/Balm', 'lip')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7pyeBEJIUnP"
      },
      "source": [
        "## Product Consistency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "acKoZ-eCKGE3",
        "outputId": "5f7556c9-9ab3-41f2-907f-5fa25d388ce4"
      },
      "source": [
        "file_path = 'drive/MyDrive/+Renzoe Box/Administrative/Team Resources/Team Folders/+2021 Fall Cohort - Group Projects/Taggers/RenzoeBoxV_sample800_NLP_sprint_trainingset.csv'\n",
        "pcdataset = pd.read_csv(file_path)\n",
        "pcdataset.head(3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>handle</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>vendor</th>\n",
              "      <th>type</th>\n",
              "      <th>tags</th>\n",
              "      <th>image src</th>\n",
              "      <th>pod nonpod</th>\n",
              "      <th>product consistency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5301</td>\n",
              "      <td>skin-glazing</td>\n",
              "      <td>skin glazing</td>\n",
              "      <td>\\ndescription\\nnabla skin glazing is a kaleido...</td>\n",
              "      <td>NABLA</td>\n",
              "      <td>highlighter</td>\n",
              "      <td>['face', 'pod']</td>\n",
              "      <td>https://images.ulta.com/is/image/Ulta/2558304</td>\n",
              "      <td>pod</td>\n",
              "      <td>pressed powder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>infallible-fresh-wear-24hr-foundation</td>\n",
              "      <td>infallible fresh wear 24hr foundation</td>\n",
              "      <td>\\ndescription\\nbe unstoppable. introducing l'o...</td>\n",
              "      <td>L'Or??al</td>\n",
              "      <td>foundation</td>\n",
              "      <td>['face', 'non-pod']</td>\n",
              "      <td>https://images.ulta.com/is/image/Ulta/2538150</td>\n",
              "      <td>non-pod</td>\n",
              "      <td>liquid, bottle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14007</td>\n",
              "      <td>sos-primer</td>\n",
              "      <td>sos primer</td>\n",
              "      <td>\\ndescription\\nprime time! discover solutions ...</td>\n",
              "      <td>Clarins</td>\n",
              "      <td>face primer</td>\n",
              "      <td>['face', 'non-pod']</td>\n",
              "      <td>https://images.ulta.com/is/image/Ulta/2523525</td>\n",
              "      <td>non-pod</td>\n",
              "      <td>liquid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                 handle  ... pod nonpod product consistency\n",
              "0   5301                           skin-glazing  ...        pod      pressed powder\n",
              "1   1462  infallible-fresh-wear-24hr-foundation  ...    non-pod      liquid, bottle\n",
              "2  14007                             sos-primer  ...    non-pod              liquid\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O20A6bsDIZUU"
      },
      "source": [
        "pcdata = pcdataset[['handle', 'title', 'body', 'product consistency']]\n",
        "\n",
        "# transfer every '-' to be NAN\n",
        "pcdata = pcdata.replace('-', np.nan)\n",
        "pcdata = pcdata.dropna()\n",
        "pcdata = pcdata.drop_duplicates()\n",
        "\n",
        "pcdata['text'] = pcdata['handle'] + \" \" + pcdata['title'] + \" \" + pcdata['body']\n",
        "pcdata = NLPCleaning(pcdata)\n",
        "pcdata_y = pcdata['product consistency']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot-ciROYIZXW",
        "outputId": "a6f27997-f5af-4119-a0af-6aa075719782"
      },
      "source": [
        "for i in range(len(pcdata)):\n",
        "\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].lstrip(\" \")\n",
        "\n",
        "  #replace all the typos\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('liquid, tube', 'liquid')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('liquid, bottle', 'liquid')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('solid stick', 'stick')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('cream, tube', 'cream')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('tube', 'pencil')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('pressed powder, palette', 'pressed powder')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('cream, liquid', 'liquid')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('pencil, tube', 'pencil')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('cream, cake', 'cream')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('liquid, pencil', 'pencil')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('gel', 'liquid')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('cream, pencil', 'pencil')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('balm', 'cream')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('cream, solid stick', 'stick')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('eyelashes', 'TOOLS')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('cream to powder', 'cream')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('gel, tube', 'liquid')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('solid stick, pencil', 'stick')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('tube, pencil', 'pencil')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('PHOTO DOESNT MATCH', \"PHOTO DOESN'T MATCH\")\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('SKINCARE', 'TOOLS')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('pencil, pencil', 'pencil')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('liquid, pencil', 'liquid')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('stick, pencil', 'pencil')\n",
        "  pcdata['product consistency'].values[i] = pcdata['product consistency'].values[i].replace('cream, stick', 'cream')\n",
        "\n",
        "pcdata = pcdata[~(pcdata['product consistency'] == \"PHOTO DOESN'T MATCH\" )]\n",
        "pcdata = pcdata[~(pcdata['product consistency'] == \"loose powder\" )]\n",
        "\n",
        "X_pc = pcdata['text']\n",
        "pcdata_y = pcdata['product consistency']\n",
        "print(X_pc.shape)\n",
        "print(pcdata_y.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(541,)\n",
            "(541,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUhbo7mR0eMy"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueakeRUDBo_Q"
      },
      "source": [
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Finish\n",
        "X_train_f, X_test_f, f_y_train, f_y_test = train_test_split(X_f, fdata_y, test_size=0.33)\n",
        "f_model_name = 'finish_finalized_model.sav'\n",
        "f_vec = 'finish_vectorizer.sav'\n",
        "\n",
        "f_loaded_model = pickle.load(open(f_model_name, 'rb'))\n",
        "f_loaded_vec = pickle.load(open(f_vec, 'rb'))\n",
        "\n",
        "X_test_f = f_loaded_vec.transform(X_test_f)\n",
        "f_y_pred = f_loaded_model.predict(X_test_f)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bZJJKFFltL"
      },
      "source": [
        "# Coverage Type\n",
        "X_train_ct, X_test_ct, ct_y_train, ct_y_test = train_test_split(X_ct, ctdata_y, test_size=0.33)\n",
        "\n",
        "ct_model_name = 'coverage_type_finalized_model.sav'\n",
        "ct_vec = 'coverage_type_vectorizer.sav'\n",
        "\n",
        "ct_loaded_model = pickle.load(open(ct_model_name, 'rb'))\n",
        "ct_loaded_vec = pickle.load(open(ct_vec, 'rb'))\n",
        "\n",
        "X_test_ct = ct_loaded_vec.transform(X_test_ct)\n",
        "ct_y_pred = ct_loaded_model.predict(X_test_ct)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l5YemYlHOWE"
      },
      "source": [
        "## Product Type\n",
        "X_train_pt, X_test_pt, pt_y_train, pt_y_test = train_test_split(X_pt, ptdata_y, test_size=0.33)\n",
        "\n",
        "pt_model_name = 'product_type_finalized_model.sav'\n",
        "pt_vec = 'product_type_vectorizer.sav'\n",
        "\n",
        "pt_loaded_model = pickle.load(open(pt_model_name, 'rb'))\n",
        "pt_loaded_vec = pickle.load(open(pt_vec, 'rb'))\n",
        "\n",
        "X_test_pt = pt_loaded_vec.transform(X_test_pt)\n",
        "pt_y_pred = pt_loaded_model.predict(X_test_pt)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sKduQQMJBMW"
      },
      "source": [
        "## Product Consistency\n",
        "X_train_pc, X_test_pc, pc_y_train, pc_y_test = train_test_split(X_pc, pcdata_y, test_size = 0.33)\n",
        "\n",
        "pc_model_name = 'product_consistency_finalized_model.sav'\n",
        "pc_vec = 'product_consistency_vectorizer.sav'\n",
        "\n",
        "pc_loaded_model = pickle.load(open(pc_model_name, 'rb'))\n",
        "pc_loaded_vec = pickle.load(open(pc_vec, 'rb'))\n",
        "\n",
        "X_test_pc = pc_loaded_vec.transform(X_test_pc)\n",
        "pc_y_pred = pc_loaded_model.predict(X_test_pc)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_zYF3N4MKwd",
        "outputId": "d244dae0-19a6-402c-81e7-1577b68ccdd1"
      },
      "source": [
        "# Product Preference\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "X_train_pp, X_test_pp, pp_y_train, pp_y_test = train_test_split(X_pp, new_ppdata_y, test_size = 0.33)\n",
        "\n",
        "pp_model_name = 'product_preference_finalized_model.sav'\n",
        "pp_vec = 'product_preference_vectorizer.sav'\n",
        "pp_mlb = 'product_preference_mlb.sav'\n",
        "\n",
        "pp_loaded_model = pickle.load(open(pp_model_name, 'rb'))\n",
        "pp_loaded_vec = pickle.load(open(pp_vec, 'rb'))\n",
        "pp_loaded_mlb = pickle.load(open(pp_mlb, 'rb'))\n",
        "\n",
        "pp_train_labels = pp_loaded_mlb.fit_transform(pp_y_train)\n",
        "pp_test_labels = pp_loaded_mlb.transform(pp_y_test)\n",
        "\n",
        "X_test_pp = pp_loaded_vec.transform(X_test_pp)\n",
        "pp_y_pred = pp_loaded_model.predict(X_test_pp)\n",
        "pp_pred_labels = pp_loaded_mlb.transform(pp_y_pred)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:876: UserWarning: unknown class(es) ['usa made'] will be ignored\n",
            "  \"unknown class(es) {0} will be ignored\".format(sorted(unknown, key=str))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:876: UserWarning: unknown class(es) [0, 1] will be ignored\n",
            "  \"unknown class(es) {0} will be ignored\".format(sorted(unknown, key=str))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI4w3zKIMMQM",
        "outputId": "bc81661c-9177-4bc8-a4ae-974d2652d80d"
      },
      "source": [
        "# Skin Concern\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "X_train_sc, X_test_sc, sc_y_train, sc_y_test = train_test_split(X_sc, scdata_y, test_size=0.33)\n",
        "\n",
        "sc_model_name = 'skin_concern_finalized_model.sav'\n",
        "sc_vec = 'skin_concern_vectorizer.sav'\n",
        "sc_mlb = 'skin_concern_mlb.sav'\n",
        "\n",
        "sc_loaded_model = pickle.load(open(sc_model_name, 'rb'))\n",
        "sc_loaded_vec = pickle.load(open(sc_vec, 'rb'))\n",
        "sc_loaded_mlb = pickle.load(open(sc_mlb, 'rb'))\n",
        "\n",
        "sc_train_labels = sc_loaded_mlb.fit_transform(sc_y_train)\n",
        "sc_test_labels = sc_loaded_mlb.transform(sc_y_test)\n",
        "\n",
        "X_test_sc = sc_loaded_vec.transform(X_test_sc)\n",
        "sc_y_pred = sc_loaded_model.predict(X_test_sc)\n",
        "sc_pred_labels = mlb.transform(sc_y_pred)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:876: UserWarning: unknown class(es) [0, 1] will be ignored\n",
            "  \"unknown class(es) {0} will be ignored\".format(sorted(unknown, key=str))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVRVwM11JB4s"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZHVK8aHngRU"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
        "ModelsPerformance = {}\n",
        "\n",
        "def metricsReport_new(modelName, test_labels, predictions):\n",
        "\n",
        "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
        "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
        "    \n",
        "    hamLoss = hamming_loss(test_labels, predictions)\n",
        "    ModelsPerformance[modelName] = micro_f1\n",
        "    max_score = max(micro_f1, macro_f1, hamLoss)\n",
        "    \n",
        "    return modelName, max_score"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "zi4jI7BmoFYx",
        "outputId": "1b39729c-277b-414f-d83e-97c2975d9916"
      },
      "source": [
        "# Unique label\n",
        "f_scores = metricsReport_new(f_loaded_model, f_y_test, f_y_pred)\n",
        "ct_scores = metricsReport_new(ct_loaded_model, ct_y_test, ct_y_pred)\n",
        "pt_scores = metricsReport_new(pt_loaded_model, pt_y_test, pt_y_pred)\n",
        "pc_scores = metricsReport_new(pc_loaded_model, pc_y_test, pc_y_pred)\n",
        "\n",
        "# Multi-label\n",
        "pp_scores = metricsReport_new(pp_loaded_model, pp_test_labels, pp_pred_labels)\n",
        "sc_scores = metricsReport_new(sc_loaded_model, sc_test_labels, sc_pred_labels)\n",
        "\n",
        "results = pd.DataFrame([f_scores, ct_scores, pt_scores, pc_scores, pp_scores, sc_scores], \n",
        "                       columns = [\"model\", \"score\"], \n",
        "                       index = ['Finish', 'Coverage Type', 'Product Type', \n",
        "                              'Product Consistency', 'Product Preference', 'Skin Concern'])\n",
        "results"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Finish</th>\n",
              "      <td>MLPClassifier(alpha=0.01, hidden_layer_sizes=(...</td>\n",
              "      <td>0.871560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coverage Type</th>\n",
              "      <td>SVC(C=10, kernel='sigmoid', random_state=1)</td>\n",
              "      <td>0.901961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Product Type</th>\n",
              "      <td>SVC(C=10, kernel='sigmoid', random_state=1)</td>\n",
              "      <td>0.988816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Product Consistency</th>\n",
              "      <td>SVC()</td>\n",
              "      <td>0.849162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Product Preference</th>\n",
              "      <td>DecisionTreeClassifier()</td>\n",
              "      <td>0.245690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skin Concern</th>\n",
              "      <td>OneVsRestClassifier(estimator=LinearSVC(), n_j...</td>\n",
              "      <td>0.273224</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 model     score\n",
              "Finish               MLPClassifier(alpha=0.01, hidden_layer_sizes=(...  0.871560\n",
              "Coverage Type              SVC(C=10, kernel='sigmoid', random_state=1)  0.901961\n",
              "Product Type               SVC(C=10, kernel='sigmoid', random_state=1)  0.988816\n",
              "Product Consistency                                              SVC()  0.849162\n",
              "Product Preference                            DecisionTreeClassifier()  0.245690\n",
              "Skin Concern         OneVsRestClassifier(estimator=LinearSVC(), n_j...  0.273224"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}